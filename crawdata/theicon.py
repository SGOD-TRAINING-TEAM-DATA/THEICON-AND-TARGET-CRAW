import os
import json
import requests
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from urllib.parse import urlparse, urljoin
from kafka import KafkaProducer

# --- CHANGED: topic and output paths ---
TOPIC = "theicon-topic"
OUTPUT_JSON = os.path.join("output", f"{TOPIC}_products.json")
IMAGES_FOLDER = os.path.join("output", "images", TOPIC)
os.makedirs(IMAGES_FOLDER, exist_ok=True)
os.makedirs("output", exist_ok=True)

# H√†m helper ch·ªçn URL t·ª´ srcset
def pick_from_srcset(srcset):
    try:
        parts = [p.strip() for p in srcset.split(',') if p.strip()]
        # ch·ªçn URL c√≥ ƒë·ªô ph√¢n gi·∫£i cao nh·∫•t (th∆∞·ªùng l√† ph·∫ßn cu·ªëi)
        last = parts[-1]
        url = last.split()[0]
        return url
    except:
        return None

# H√†m download ·∫£nh - ƒë√£ s·ª≠a ƒë·ªÉ x·ª≠ l√Ω t·ªët h∆°n v√† c√≥ retry
def download_image(img_url, folder_path, filename):
    try:
        if not img_url:
            print(f" URL ·∫£nh kh√¥ng h·ª£p l·ªá: {img_url}")
            return None

        # ƒë·∫£m b·∫£o folder t·ªìn t·∫°i
        os.makedirs(folder_path, exist_ok=True)
        
        # n·∫øu l√† srcset th√¨ l·∫•y 1 URL
        if ',' in img_url and ' ' in img_url:
            picked = pick_from_srcset(img_url)
            if picked:
                img_url = picked

        if not img_url.startswith(('http://', 'https://')):
            print(f" URL ·∫£nh kh√¥ng b·∫Øt ƒë·∫ßu b·∫±ng http(s), b·ªè qua: {img_url}")
            return None

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://www.theiconic.com.au/'
        }

        # retry ƒë∆°n gi·∫£n
        last_exc = None
        for attempt in range(3):
            try:
                print(f" ƒêang t·∫£i ·∫£nh t·ª´: {img_url} (attempt {attempt+1})")
                response = requests.get(img_url, headers=headers, timeout=30, stream=True)
                response.raise_for_status()
                content_type = response.headers.get('content-type', '')
                if 'image' not in content_type:
                    print(f"  C·∫£nh b√°o: content-type kh√¥ng ph·∫£i image: {content_type}")
                # L·∫•y extension t·ª´ path
                parsed_url = urlparse(img_url)
                file_ext = os.path.splitext(parsed_url.path)[1]
                if not file_ext:
                    if 'jpeg' in content_type or 'jpg' in content_type:
                        file_ext = '.jpg'
                    elif 'png' in content_type:
                        file_ext = '.png'
                    elif 'webp' in content_type:
                        file_ext = '.webp'
                    else:
                        file_ext = '.jpg'

                safe_name = filename.replace('/', '_').replace('\\', '_').replace(':', '_').strip()
                file_path = os.path.join(folder_path, f"{safe_name}{file_ext}")

                # ghi file theo chunk
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(1024 * 8):
                        if chunk:
                            f.write(chunk)

                file_size = os.path.getsize(file_path)
                print(f" ƒê√£ t·∫£i ·∫£nh: {os.path.basename(file_path)} ({file_size} bytes)")
                return os.path.basename(file_path)

            except Exception as e:
                last_exc = e
                print(f"  L·ªói t·∫£i ·∫£nh (attempt {attempt+1}): {e}")
                time.sleep(1)
                continue

        print(f" Th·∫•t b·∫°i t·∫£i ·∫£nh sau 3 l·∫ßn: {last_exc}")
        return None

    except Exception as e:
        print(f" L·ªói t·ªïng qu√°t khi t·∫£i ·∫£nh {filename}: {e}")
        return None

# Setup driver
driverpath = r"D:\chromedriver-win64\chromedriver.exe"
service = Service(driverpath)
options = webdriver.ChromeOptions()
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("--window-size=1920,1080")
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")

driver = webdriver.Chrome(service=service, options=options)
driver.set_page_load_timeout(30)  # Page load timeout
driver.set_script_timeout(30)     # Script timeout
driver.implicitly_wait(10)        # Implicit wait for elements
wait = WebDriverWait(driver, 20)  # Explicit wait object

# T·∫°o Kafka producer
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda x: json.dumps(x).encode('utf-8')
)

# Truy c·∫≠p trang
url = "https://www.theiconic.com.au/all?campaign=lp-gtm-w-gifts-oct25"
print(" ƒêang t·∫£i trang...")
driver.get(url)
time.sleep(10)

def safe_scroll(driver, retries=3, scroll_pause=2.0):
    """Safely scroll with retries and error handling"""
    for attempt in range(retries):
        try:
            # Get current scroll position
            current = driver.execute_script("return window.pageYOffset;")
            
            # Scroll in smaller increments
            driver.execute_script("""
                window.scrollTo({
                    top: window.pageYOffset + 800,
                    behavior: 'smooth'
                });
            """)
            
            # Wait for scroll
            time.sleep(scroll_pause)
            
            # Check if actually scrolled
            new_position = driver.execute_script("return window.pageYOffset;")
            if new_position > current:
                return True
            
        except Exception as e:
            print(f"[WARN] Scroll attempt {attempt + 1} failed: {str(e)}")
            time.sleep(scroll_pause)
    
    return False

# Scroll ƒë·ªÉ load s·∫£n ph·∫©m
print(" ƒêang t·∫£i t·∫•t c·∫£ s·∫£n ph·∫©m...")
for i in range(8):
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    print(f" Scroll l·∫ßn {i+1}/8")
    time.sleep(2)

time.sleep(5)

print("ƒêang thu th·∫≠p d·ªØ li·ªáu s·∫£n ph·∫©m...")
products_data = []

try:
    # Initial wait for page load
    time.sleep(5)
    
    # Scroll with improved error handling
    scroll_count = 0
    max_scrolls = 10
    
    while scroll_count < max_scrolls:
        # Try to scroll
        if not safe_scroll(driver, retries=3, scroll_pause=2.0):
            print("[INFO] Reached bottom or scroll failed")
            break
            
        scroll_count += 1
        print(f"Scroll {scroll_count}/{max_scrolls}")
        
        # Find products after each scroll
        product_containers = driver.find_elements(By.CSS_SELECTOR, "#catalogProductsList > div")
        if len(product_containers) >= 50:  # Or your desired minimum
            print(f"Found enough products: {len(product_containers)}")
            break
    
    print(f"T√¨m th·∫•y {len(product_containers)} s·∫£n ph·∫©m (container)")
    
    for container in product_containers:
        try:
            # L·∫•y t√™n s·∫£n ph·∫©m tr∆∞·ªõc h·∫øt
            name = ""
            try:
                name_elem = container.find_element(By.CSS_SELECTOR, "span.name")
                name = name_elem.text.strip()
            except:
                print(" Kh√¥ng t√¨m th·∫•y t√™n, b·ªè qua container")
                continue

            # L·∫•y brand
            brand = ""
            try:
                if " - " in name:
                    brand = name.split(" - ")[0].strip()
                else:
                    brand_elem = container.find_element(By.CSS_SELECTOR, "span.brand")
                    brand = brand_elem.text.strip()
            except:
                brand = ""

            # Discount (l·∫•y s·ªõm ƒë·ªÉ d√πng khi c·∫ßn t√≠nh gi√°)
            discount = ""
            try:
                discount_elem = container.find_element(By.CSS_SELECTOR, "span.message.marketing.warp-extended-text")
                discount = discount_elem.text.strip()
            except:
                discount = ""

            # Gi√°
            price_original = ""
            price_final = ""
            try:
                original_elem = container.find_element(By.CSS_SELECTOR, "div.price.original, span.price.original")
                price_original = original_elem.text.strip()
            except:
                pass

            try:
                final_elem = container.find_element(By.CSS_SELECTOR, "div.price.final, span.price.final, span.price")
                price_final = final_elem.text.strip()
            except:
                # n·∫øu kh√¥ng t√¨m th·∫•y final th√¨ v·∫´n ti·∫øp t·ª•c (site c√≥ th·ªÉ show only original)
                price_final = price_final or ""

            # N·∫øu gi√° gh√©p sai (final == original) nh∆∞ng c√≥ discount d·∫°ng "NN% OFF", t√≠nh l·∫°i final
            def parse_price(p):
                try:
                    import re
                    if not p:
                        return None
                    m = re.search(r'[\d\.,]+', p)
                    if not m:
                        return None
                    s = m.group(0).replace(',', '')
                    return float(s)
                except:
                    return None

            def format_price(v):
                if v is None:
                    return ""
                # gi·ªØ 2 ch·ªØ s·ªë th·∫≠p ph√¢n nh∆∞ site
                return f"${v:,.2f}"

            # chu·∫©n h√≥a v√† s·ª≠a n·∫øu c·∫ßn
            try:
                orig_val = parse_price(price_original)
                final_val = parse_price(price_final)
                # t√¨m percent trong discount (v√≠ d·ª• "25% OFF...")
                import re
                pct = None
                m_pct = re.search(r'(\d{1,3})\s*%', discount or "", re.IGNORECASE)
                if m_pct:
                    pct = float(m_pct.group(1)) / 100.0

                if pct is not None and orig_val is not None:
                    calc_final = round(orig_val * (1.0 - pct), 2)
                    # n·∫øu final kh√¥ng t√¨m ƒë∆∞·ª£c ho·∫∑c final == original (ch∆∞a gi·∫£m) ho·∫∑c ch√™nh nhi·ªÅu, c·∫≠p nh·∫≠t
                    if final_val is None or abs((final_val or 0) - calc_final) > 0.01 or (final_val == orig_val):
                        price_final = format_price(calc_final)
                        # gi·ªØ price_original nh∆∞ ban ƒë·∫ßu (site c√≥ th·ªÉ hi·ªÉn th·ªã c·∫£ hai)
                        print(f"  ƒêi·ªÅu ch·ªânh price_final => {price_final} (t·ª´ {price_original}, gi·∫£m {int(pct*100)}%)")
            except Exception as e:
                print(f"  L·ªói x·ª≠ l√Ω gi√°: {e}")
            # Discount
            discount = ""
            try:
                discount_elem = container.find_element(By.CSS_SELECTOR, "span.message.marketing.warp-extended-text")
                discount = discount_elem.text.strip()
            except:
                discount = ""

            # ·∫¢nh: th·ª≠ nhi·ªÅu attribute, x·ª≠ l√Ω srcset, relative URL
            image_url = ""
            try:
                img_elem = None
                selectors = ["a.product-image-link img", "img[src*='static.theiconic.com.au']", "img.product-image", "img[data-src*='static.theiconic.com.au']", "img"]
                for sel in selectors:
                    try:
                        img_elem = container.find_element(By.CSS_SELECTOR, sel)
                        if img_elem:
                            break
                    except:
                        img_elem = None
                if img_elem:
                    # ∆∞u ti√™n src, data-src, data-lazy-src, srcset
                    image_url = img_elem.get_attribute("src") or img_elem.get_attribute("data-src") or img_elem.get_attribute("data-lazy-src") or img_elem.get_attribute("data-srcset") or img_elem.get_attribute("srcset")
                    if image_url and (image_url.startswith("//")):
                        image_url = "https:" + image_url
                    if image_url and not image_url.startswith("http"):
                        image_url = urljoin(url, image_url)
                else:
                    image_url = ""
            except Exception as e:
                print(f" L·ªói l·∫•y ·∫£nh: {e}")
                image_url = ""

            # Chu·∫©n b·ªã filename v√† seq d·ª±a tr√™n s·ªë s·∫£n ph·∫©m ƒë√£ l∆∞u (tr√°nh ƒë√°nh nh·∫ßm)
            seq = len(products_data) + 1
            safe_brand = "".join(c for c in brand if c.isalnum() or c in (' ', '-', '_')).rstrip() or "unknown_brand"
            safe_name = "".join(c for c in name if c.isalnum() or c in (' ', '-', '_')).rstrip() or "unknown_product"
            filename_base = f"{seq:03d}_{safe_brand}_{safe_name}"
            filename_base = "".join(c for c in filename_base if c.isalnum() or c in (' ', '-', '_')).rstrip()
            filename_base = filename_base[:50]

            image_filename = None
            if image_url:
                image_filename = download_image(image_url, IMAGES_FOLDER, filename_base)
            else:
                print(" Kh√¥ng t√¨m th·∫•y URL ·∫£nh, b·ªè qua t·∫£i ·∫£nh")

            product_info = {
                "id": seq,
                "brand": brand,
                "name": name,
                "price_original": price_original,
                "price_final": price_final,
                "discount": discount,
                "image_url": image_url,
                "image_filename": image_filename
            }

            # G·ª≠i v√†o Kafka
            producer.send(TOPIC, product_info)
            producer.flush()

            products_data.append(product_info)
            print(f"ƒê√£ th√™m v√† g·ª≠i Kafka s·∫£n ph·∫©m #{seq}: {brand} - {name}")

        except Exception as e:
            print(f" L·ªói x·ª≠ l√Ω 1 s·∫£n ph·∫©m: {e}")
            continue

except Exception as e:
    print(f" L·ªói thu th·∫≠p d·ªØ li·ªáu: {e}")

# ƒê√≥ng producer khi ho√†n th√†nh
finally:
    producer.close()
    driver.quit()

# L∆∞u d·ªØ li·ªáu ri√™ng theo topic
with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
    json.dump(products_data, f, ensure_ascii=False, indent=2)

print(f"\nüéâ HO√ÄN TH√ÄNH! ƒê√£ l∆∞u {len(products_data)} s·∫£n ph·∫©m v√†o {OUTPUT_JSON}")
# ƒê·∫øm s·ªë ·∫£nh ƒë√£ t·∫£i th√†nh c√¥ng
downloaded_count = sum(1 for p in products_data if p.get('image_filename'))
print(f"üñºÔ∏è ƒê√£ t·∫£i {downloaded_count} ·∫£nh")

# Hi·ªÉn th·ªã k·∫øt qu·∫£ chi ti·∫øt
if products_data:
    print(f"\n CHI TI·∫æT S·∫¢N PH·∫®M:")
    for product in products_data:
        print(f"\n{product['id']}. {product['brand']} - {product['name']}")
        print(f"    Gi√° g·ªëc: {product['price_original'] or 'Kh√¥ng c√≥'}")
        print(f"    Gi√° hi·ªán t·∫°i: {product['price_final']}")
        if product['discount']:
            print(f"    Khuy·∫øn m√£i: {product['discount']}")
        print(f"   URL ·∫£nh: {product['image_url'][:100] if product['image_url'] else 'Kh√¥ng c√≥'}...")
        if product['image_filename']:
            print(f"    File ·∫£nh: {product['image_filename']}")
        else:
            print(f"    Kh√¥ng c√≥ file ·∫£nh")
        print("-" * 100)
else:
    print(" Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ƒë∆∞·ª£c thu th·∫≠p")